"""
train_lightgbm_with_embeddings.py

åŠŸèƒ½ï¼š
1. åŠ è½½ embedding æ•°æ® (CSV)
2. å¯é€‰ PCA é™ç»´
3. ä½¿ç”¨ LightGBM è®­ç»ƒå›å½’æ¨¡å‹
4. è¾“å‡º RÂ² / RMSE / MAE
5. ä¿å­˜é¢„æµ‹ç»“æœ
"""

import pandas as pd
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error


# =========================
# é…ç½®
# =========================
INPUT_FILE = "../../../mid_result/training_data/test_scored_16K_QwenEmbeddings.csv"  # è¾“å…¥ embedding CSV
OUTPUT_FILE = "../train/lightgbm_predictions.csv"  # è¾“å‡ºé¢„æµ‹ç»“æœ CSV
USE_PCA = True
PCA_DIM = 300
TEST_SIZE = 0.2
RANDOM_STATE = 42


# =========================
# Step 1: åŠ è½½æ•°æ®
# =========================
def load_data(input_file):
    df = pd.read_csv(input_file)
    X = df[[col for col in df.columns if col.startswith("emb_")]]
    y = df["åˆ†æ•°"]
    print(f"ğŸ“¥ æ•°æ®åŠ è½½å®Œæˆ: {X.shape[0]} è¡Œ, {X.shape[1]} ç»´")
    return df, X, y


# =========================
# Step 2: é™ç»´ (å¯é€‰)
# =========================
def reduce_dimensionality(X, use_pca=True, dim=200, random_state=42):
    if use_pca:
        pca = PCA(n_components=dim, random_state=random_state)
        X_reduced = pca.fit_transform(X)
        print(f"ğŸ“‰ å·²é™ç»´: {X.shape[1]} -> {X_reduced.shape[1]}")
        return X_reduced, pca
    else:
        print("â¡ï¸ è·³è¿‡ PCA é™ç»´")
        return X, None


# =========================
# Step 3: åˆ’åˆ†æ•°æ®é›†
# =========================
def split_data(X, y, test_size=0.2, random_state=42):
    return train_test_split(X, y, test_size=test_size, random_state=random_state)


# =========================
# Step 4: è®­ç»ƒ LightGBM
# =========================
def train_lightgbm(X_train, y_train, random_state=42):
    model = lgb.LGBMRegressor(
        n_estimators=500,
        learning_rate=0.05,
        num_leaves=64,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=random_state
    )
    print("â³ æ­£åœ¨è®­ç»ƒ LightGBM...")
    model.fit(X_train, y_train)
    print("âœ… è®­ç»ƒå®Œæˆ")
    return model


# =========================
# Step 5: è¯„ä¼°æ¨¡å‹
# =========================
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    rmse = mean_squared_error(y_test, y_pred) ** 0.5  # å…¼å®¹æ—§ç‰ˆ
    mae = mean_absolute_error(y_test, y_pred)

    print("\nğŸ“Š æ¨¡å‹è¡¨ç°ï¼š")
    print(f"RÂ²     = {r2:.4f}")
    print(f"RMSE   = {rmse:.4f}")
    print(f"MAE    = {mae:.4f}")
    return y_pred, r2, rmse, mae



# =========================
# Step 6: ä¿å­˜é¢„æµ‹ç»“æœ
# =========================
def save_results(y_test, y_pred, output_file):
    df_out = pd.DataFrame({
        "çœŸå®åˆ†æ•°": y_test,
        "é¢„æµ‹åˆ†æ•°": y_pred
    })
    df_out.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"ğŸ’¾ å·²ä¿å­˜é¢„æµ‹ç»“æœåˆ° {output_file}")


# =========================
# ä¸»æµç¨‹
# =========================
def main():
    # Step 1: åŠ è½½æ•°æ®
    df, X, y = load_data(INPUT_FILE)

    # Step 2: é™ç»´
    X, pca_model = reduce_dimensionality(X, use_pca=USE_PCA, dim=PCA_DIM, random_state=RANDOM_STATE)

    # Step 3: åˆ’åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test = split_data(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)

    # Step 4: è®­ç»ƒæ¨¡å‹
    model = train_lightgbm(X_train, y_train, random_state=RANDOM_STATE)

    # Step 5: è¯„ä¼°æ¨¡å‹
    y_pred, r2, rmse, mae = evaluate_model(model, X_test, y_test)

    # Step 6: ä¿å­˜ç»“æœ
    save_results(y_test, y_pred, OUTPUT_FILE)


if __name__ == "__main__":
    main()
