{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2025-10-14T12:49:06.002390200Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "å•æ–‡ä»¶é¢„æµ‹è„šæœ¬ï¼š\n",
    "1. åŠ è½½å·²è®­ç»ƒå¥½çš„ encoder å’Œ LightGBM\n",
    "2. è¯»å–å•ä¸ª CSV æ–‡ä»¶\n",
    "3. æŠ½å–â€œæ ‡é¢˜â€ â†’ embedding â†’ LightGBM é¢„æµ‹\n",
    "4. åœ¨åŸæ–‡ä»¶ä¸­æ–°å¢â€œåŸºç¡€åˆ†æ•°â€åˆ—å¹¶ä¿å­˜\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from lightgbm import Booster\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============== é…ç½® ===============\n",
    "MODEL_NAME = \"shibing624/text2vec-base-chinese-sentence\"\n",
    "ENCODER_PATH = \"../../../res/training_model/multitask_encoder.pt\"\n",
    "LGBM_PATH = \"../../../res/training_model/multitask_lightgbm.txt\"\n",
    "\n",
    "SENTENCE_ONLY_MODEL_PATH = \"shibing624/text2vec-base-chinese-sentence\"  # ä»…å¥å­æ¨¡å‹è·¯å¾„\n",
    "SENTENCE_ONLY_LGBM_PATH = \"../../../res/training_model/sentence_only_lightgbm.txt\"\n",
    "\n",
    "INPUT_FILE = \"../../../mid_result/training_data/merged_2w_scored_titles_LLM.csv\"  # ğŸ”¹ æŒ‡å®šè¦é¢„æµ‹çš„æ–‡ä»¶\n",
    "OUTPUT_FILE = \"multitask_and_not_compare.csv\"  # ğŸ”¹ è¾“å‡ºè·¯å¾„\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# =============== æ•°æ®é›† ===============\n",
    "class TitleDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len=32):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"text\"] = self.texts[idx]\n",
    "        return item\n",
    "\n",
    "# =============== æ¨¡å‹ç»“æ„ ===============\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, model_name, hidden_size=768):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.head_word = nn.Linear(hidden_size, 1)\n",
    "        self.head_title = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, task_type=\"title\"):\n",
    "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = out.pooler_output if out.pooler_output is not None else out.last_hidden_state[:, 0, :]\n",
    "        pooled = self.dropout(pooled)\n",
    "        return self.head_title(pooled)\n",
    "\n",
    "    def get_embedding(self, input_ids, attention_mask):\n",
    "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = out.pooler_output if out.pooler_output is not None else out.last_hidden_state[:, 0, :]\n",
    "        return pooled.detach()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-14T12:44:23.021324900Z",
     "start_time": "2025-10-14T12:44:22.984570700Z"
    }
   },
   "id": "feaf9c225fa7efeb",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# =============== åŠ è½½æ¨¡å‹ ===============\n",
    "print(f\"ğŸ”¹ å½“å‰é¢„æµ‹è®¾å¤‡: {device}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# åŠ è½½å¤šä»»åŠ¡æ¨¡å‹ï¼ˆMultiTaskModelï¼‰å’ŒLightGBMæ¨¡å‹\n",
    "encoder = MultiTaskModel(MODEL_NAME).to(device)\n",
    "encoder.load_state_dict(torch.load(ENCODER_PATH, map_location=device))\n",
    "encoder.eval()\n",
    "lgbm_model = Booster(model_file=LGBM_PATH)\n",
    "\n",
    "# åŠ è½½ä»…å¥å­æ¨¡å‹å’Œå¯¹åº”çš„LightGBM\n",
    "sentence_encoder = AutoModel.from_pretrained(SENTENCE_ONLY_MODEL_PATH).to(device)\n",
    "sentence_encoder.eval()\n",
    "sentence_lgbm_model = Booster(model_file=SENTENCE_ONLY_LGBM_PATH)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-14T12:49:06.000379700Z",
     "start_time": "2025-10-14T12:49:05.998934200Z"
    }
   },
   "id": "24be7f72b8ea3c1b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# =============== å·¥å…·å‡½æ•° ===============\n",
    "def get_embeddings(model, dataset, batch_size=64):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_vecs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Encoding embeddings\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            mask = batch[\"attention_mask\"].to(device)\n",
    "            vecs = model.get_embedding(input_ids, mask)\n",
    "            all_vecs.append(vecs.cpu().numpy())\n",
    "    return np.vstack(all_vecs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-14T12:44:28.565523100Z",
     "start_time": "2025-10-14T12:44:28.551730500Z"
    }
   },
   "id": "759fd37cf40d311b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ æ­£åœ¨å¤„ç†æ–‡ä»¶: ../../../mid_result/training_data/merged_2w_scored_titles_LLM.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 310/310 [04:35<00:00,  1.12it/s]\n",
      "Encoding embeddings:   0%|          | 0/310 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ErnieModel' object has no attribute 'get_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m y_pred_multitask = lgbm_model.predict(X_multitask)\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# è·å–ä»…å¥å­æ¨¡å‹çš„åµŒå…¥å‘é‡å¹¶é¢„æµ‹\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m X_sentence_only = get_embeddings(sentence_encoder, dataset, batch_size=BATCH_SIZE)\n\u001B[32m     18\u001B[39m y_pred_sentence_only = sentence_lgbm_model.predict(X_sentence_only)\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# å°†ä¸¤ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœæ·»åŠ åˆ°åŸå§‹ DataFrame ä¸­\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 9\u001B[39m, in \u001B[36mget_embeddings\u001B[39m\u001B[34m(model, dataset, batch_size)\u001B[39m\n\u001B[32m      7\u001B[39m         input_ids = batch[\u001B[33m\"\u001B[39m\u001B[33minput_ids\u001B[39m\u001B[33m\"\u001B[39m].to(device)\n\u001B[32m      8\u001B[39m         mask = batch[\u001B[33m\"\u001B[39m\u001B[33mattention_mask\u001B[39m\u001B[33m\"\u001B[39m].to(device)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m         vecs = model.get_embedding(input_ids, mask)\n\u001B[32m     10\u001B[39m         all_vecs.append(vecs.cpu().numpy())\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m np.vstack(all_vecs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\All_of_mine\\Tools\\Anaconda3\\envs\\my_python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001B[39m, in \u001B[36mModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1929\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[32m   1930\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[32m-> \u001B[39m\u001B[32m1931\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[32m   1932\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m).\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m object has no attribute \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1933\u001B[39m )\n",
      "\u001B[31mAttributeError\u001B[39m: 'ErnieModel' object has no attribute 'get_embedding'"
     ]
    }
   ],
   "source": [
    "# =============== ä¸»ç¨‹åº ===============\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"ğŸ“‚ æ­£åœ¨å¤„ç†æ–‡ä»¶: {INPUT_FILE}\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    if \"æ ‡é¢˜\" not in df.columns:\n",
    "        raise ValueError(f\"âŒ æœªæ‰¾åˆ°åˆ— 'æ ‡é¢˜'ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶åˆ—åã€‚å½“å‰åˆ—ä¸º: {df.columns.tolist()}\")\n",
    "\n",
    "    texts = df[\"æ ‡é¢˜\"].astype(str).tolist()\n",
    "    dataset = TitleDataset(texts, tokenizer, max_len=32)\n",
    "\n",
    "    # è·å–å¤šä»»åŠ¡æ¨¡å‹ï¼ˆMultiTaskModelï¼‰çš„åµŒå…¥å‘é‡å¹¶é¢„æµ‹\n",
    "    X_multitask = get_embeddings(encoder, dataset, batch_size=BATCH_SIZE)\n",
    "    y_pred_multitask = lgbm_model.predict(X_multitask)\n",
    "\n",
    "    # è·å–ä»…å¥å­æ¨¡å‹çš„åµŒå…¥å‘é‡å¹¶é¢„æµ‹\n",
    "    X_sentence_only = get_embeddings(sentence_encoder, dataset, batch_size=BATCH_SIZE)\n",
    "    y_pred_sentence_only = sentence_lgbm_model.predict(X_sentence_only)\n",
    "\n",
    "    # å°†ä¸¤ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœæ·»åŠ åˆ°åŸå§‹ DataFrame ä¸­\n",
    "    df[\"MultiTask_åŸºç¡€åˆ†æ•°\"] = y_pred_multitask\n",
    "    df[\"SentenceOnly_åŸºç¡€åˆ†æ•°\"] = y_pred_sentence_only\n",
    "\n",
    "    # ä¿å­˜ç»“æœ\n",
    "    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… é¢„æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-14T12:49:05.996994900Z",
     "start_time": "2025-10-14T12:44:28.567530200Z"
    }
   },
   "id": "7da685e76833c678",
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
