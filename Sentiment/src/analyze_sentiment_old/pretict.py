import pandas as pd
import torch
import joblib
import numpy as np
import os
from transformers import BertTokenizer, BertModel
from tqdm import tqdm  # è¿›åº¦æ¡

# è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
model_path = "random_forest_model.pkl"
data_dir = r"D:\All_of_mine\å¤§å­¦\é¡¹ç›®å’Œæ¯”èµ›\da_chuang\src\data_2\zssh000300"

print('ğŸ”¹ å¼€å§‹åŠ è½½æ¨¡å‹...')
# åŠ è½½ BERT é¢„è®­ç»ƒæ¨¡å‹
tokenizer = BertTokenizer.from_pretrained("bert-base-chinese")
bert_model = BertModel.from_pretrained("bert-base-chinese")

# åŠ è½½è®­ç»ƒå¥½çš„å›å½’æ¨¡å‹
regressor = joblib.load(model_path)

# ğŸ”¹ BERT ç‰¹å¾æå–ï¼ˆä½¿ç”¨ç¼“å­˜åŠ é€Ÿï¼‰
bert_cache = {}

def get_bert_embedding(text):
    """ è·å– BERT è¯å‘é‡ï¼ˆæ”¯æŒç¼“å­˜ï¼‰ """
    if text in bert_cache:
        return bert_cache[text]  # ç›´æ¥è¿”å›ç¼“å­˜

    tokens = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=10)
    with torch.no_grad():
        output = bert_model(**tokens)

    emb = output.last_hidden_state[:, 0, :].squeeze().numpy()  # å– [CLS] ä½ç½®çš„å‘é‡
    bert_cache[text] = emb  # å­˜å…¥ç¼“å­˜
    return emb


def calculate_score_for_terms(term):
    """ è®¡ç®—å•ä¸ªåˆ†è¯ç»“æœçš„é¢„æµ‹åˆ†æ•° """
    if isinstance(term, str):  # ä»…å¯¹å­—ç¬¦ä¸²å¤„ç†
        terms = term.split()  # æŒ‰ç©ºæ ¼æ‹†åˆ†
        scores = []

        for t in terms:
            emb = get_bert_embedding(t)  # è·å– BERT å‘é‡
            score = regressor.predict([emb])  # é¢„æµ‹åˆ†æ•°
            scores.append(score[0])

        return np.mean(scores) if scores else np.nan  # è®¡ç®—å¹³å‡åˆ†
    return np.nan  # éå­—ç¬¦ä¸²è¿”å› NaN


# ğŸ”¹ éå† `data_dir` ä¸‹æ‰€æœ‰å­æ–‡ä»¶å¤¹
all_files = []
for root, _, files in os.walk(data_dir):
    for file in files:
        if file == "extracted_words.xlsx":
            all_files.append(os.path.join(root, file))

if not all_files:
    print("âŒ æœªæ‰¾åˆ°ä»»ä½• `extracted_words.xlsx` æ–‡ä»¶")
    exit()

# ğŸ”¹ å¤„ç†æ‰€æœ‰æ‰¾åˆ°çš„æ–‡ä»¶
for file in all_files:
    print(f"ğŸ” æ­£åœ¨å¤„ç†: {file}")
    comments_data = pd.read_excel(file)

    # ç¡®ä¿ "åˆ†è¯ç»“æœ" åˆ—å­˜åœ¨
    if "åˆ†è¯" not in comments_data.columns:
        print(f"âš ï¸ è­¦å‘Š: {file} ç¼ºå°‘ 'åˆ†è¯ç»“æœ' åˆ—ï¼Œå·²è·³è¿‡")
        continue

    # è®¡ç®—è¯„åˆ†ï¼ˆæ˜¾ç¤ºè¿›åº¦æ¡ï¼‰
    comments_data["é¢„æµ‹åˆ†æ•°"] = [calculate_score_for_terms(text) for text in tqdm(comments_data["åˆ†è¯"])]

    # ğŸ”¹ ä¿å­˜å›åŸæ–‡ä»¶å¤¹
    output_path = os.path.join(os.path.dirname(file), "è‚¡å§è¯„è®ºåˆ†è¯ç»“æœ_å¸¦åˆ†æ•°.xlsx")
    comments_data.to_excel(output_path, index=False)
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
